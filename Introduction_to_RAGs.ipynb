{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMia8h09Epxj/o7c8+c7C63",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yashsakhuja/Introduction-to-RAG-with-LLAMA3/blob/main/Introduction_to_RAGs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "VBqTN7YAJTus"
      },
      "outputs": [],
      "source": [
        "!pip install pypdf\n",
        "!pip install -q transformers einops accelerate langchain bitsandbytes\n",
        "#For Embedding\n",
        "!pip install sentence_transformers\n",
        "\n",
        "!pip install llama_index\n",
        "!pip install llama-index-embeddings-langchain\n",
        "!pip install llama-index-llms-huggingface"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
        "from llama_index.llms.huggingface import HuggingFaceLLM\n",
        "from llama_index.core.prompts.prompts import SimpleInputPrompt"
      ],
      "metadata": {
        "collapsed": true,
        "id": "qXuEy-fPLzKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents= SimpleDirectoryReader('/content/data').load_data()"
      ],
      "metadata": {
        "id": "Ql2W_Oi0TwzI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents"
      ],
      "metadata": {
        "collapsed": true,
        "id": "agP-SC4FWHgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt=\"\"\"\n",
        "\n",
        "You are a Q&A assistant. Your goal is to answer questions as\n",
        "accurately as possible based on the instructions and context provided.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "sMfTg_JUVk_d"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Default prompt supported by llama2\n",
        "query_wrapper_prompt = SimpleInputPrompt(\"<|USER|>{query_str}<|ASSISTANT|>\")"
      ],
      "metadata": {
        "id": "7pAggBOGWgUl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "Y5vgD_JHXB0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "VqVhFJaVYX4x"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFaceLLM(\n",
        "    context_window=4096,\n",
        "    max_new_tokens=256,\n",
        "    generate_kwargs={\"temperature\": 0.0, \"do_sample\": False},\n",
        "    system_prompt=system_prompt,\n",
        "    query_wrapper_prompt=query_wrapper_prompt,\n",
        "    tokenizer_name=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
        "    model_name=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
        "    device_map=\"auto\",\n",
        "    # loading model in 8bit for reducing memory\n",
        "    model_kwargs={\"torch_dtype\": torch.float16 , \"load_in_8bit\":True}\n",
        ")"
      ],
      "metadata": {
        "id": "YYyKio4eZnU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
        "from llama_index.core import ServiceContext\n",
        "from llama_index.legacy.embeddings.langchain import LangchainEmbedding"
      ],
      "metadata": {
        "id": "XH7KmXVejFCy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_model= LangchainEmbedding(HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\"))"
      ],
      "metadata": {
        "id": "kwC94nPdlY4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "service_context=ServiceContext.from_defaults(\n",
        "    chunk_size=1024,\n",
        "    llm=llm,\n",
        "    embed_model=embed_model\n",
        ")"
      ],
      "metadata": {
        "id": "o7h8cEMkl2SZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "service_context"
      ],
      "metadata": {
        "id": "zKEKtj5cmSfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index=VectorStoreIndex.from_documents(documents,service_context=service_context)"
      ],
      "metadata": {
        "id": "eqRSTVPJmZtL"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine=index.as_query_engine()"
      ],
      "metadata": {
        "id": "_tAB7aqVmhl1"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response=query_engine.query(\"What are the rules regarding hitting the ball twice?\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "s7Dmf5ZYmrLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "id": "26bZocjInaTm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}